import re
from openai import OpenAI

import os
from openai import OpenAI

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))


def clean_repetitions(text):
    text = re.sub(r'(\S+)( \1)+', r'\1', text)
    text = re.sub(r'(\d{4}[ë…„.]\d{2}[ì›”.]\d{2}[ì¼.]?)( \1)+', r'\1', text)
    return text.strip()

def clean_intro(text):
    bad_phrases = ["ì•ˆë…•í•˜ì„¸ìš”", "ì €ëŠ” ë‚´ë‹´ì", "ì§ˆë¬¸ì„ í•˜ì…¨ëŠ”ë°ìš”", "ğŸ˜Š", "ğŸ˜Œ"]
    for phrase in bad_phrases:
        if phrase in text:
            text = text.split(phrase, 1)[-1]
    return text.strip()

# âœ… OpenAI API ì‘ë‹µ í•¨ìˆ˜ (v1.x êµ¬ì¡°)
def get_openai_answer(user_prompt, system_prompt, max_tokens=300):
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        temperature=0.7,
        max_tokens=max_tokens
    )
    return clean_intro(clean_repetitions(response.choices[0].message.content.strip()))


class generator:
    def __init__(self, llm="openai", model=None, tokenizer=None):
        self.llm = llm
        self.history = []

        self.default_system_prompt = (
            "ë‹¹ì‹ ì€ ë‚´ë‹´ìì˜ ê³ ë¯¼ì„ ê³µê°í•˜ë©° ì§§ê³  ë”°ëœ»í•˜ê²Œ ì¡°ì–¸í•˜ëŠ” ì‹¬ë¦¬ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.\n"
            "ì ˆëŒ€ ì¸ì‚¬ë§ì´ë‚˜ ì§ˆë¬¸ ë°˜ë³µ ì—†ì´ ë°”ë¡œ í•µì‹¬ ì¡°ì–¸ë¶€í„° ì‹œì‘í•˜ì„¸ìš”.\n"
            "ë‹µë³€ì€ 2~3ë¬¸ì¥ ì´ë‚´ë¡œ ëë‚´ê³ , 80ë‹¨ì–´ ì´í•˜ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë§ˆë¬´ë¦¬í•˜ì„¸ìš”.\n"
            "ì˜ˆ: 'ì¡°ê¸ˆ ì‰¬ëŠ” ê²ƒë„ ê´œì°®ì•„ìš”. ë‚˜ë¥¼ ìœ„í•œ ì‹œê°„ì„ ê°€ì ¸ë³´ì„¸ìš”.'"
        )

    def get_llm_output(self, prompt):
        return get_openai_answer(
            user_prompt=prompt,
            system_prompt=self.default_system_prompt
        )

    def direct_answer(self, question):
        prompt = f"ğŸ™‹ ë‚´ë‹´ì ê³ ë¯¼:\n{question}\n\nğŸ’¬ ìƒë‹´ì‚¬ ì‘ë‹µ:"
        return self.get_llm_output(prompt)

    def rag_answer(self, question, reference):
        prompt = (
            f"ğŸ“š ì‹¬ë¦¬ìƒë‹´ ì´ë¡  ì°¸ê³ :\n{reference}\n\n"
            f"ğŸ™‹ ë‚´ë‹´ì ê³ ë¯¼:\n{question}\n\nğŸ’¬ ìƒë‹´ì‚¬ ì‘ë‹µ:"
        )
        return self.get_llm_output(prompt)

    def full_answer_with_history(self, question, reference, memory):
        prompt = (
            f"ğŸ§  ê³¼ê±° ìƒë‹´ ë‚´ìš©:\n{memory}\n\n"
            f"ğŸ“š ì‹¬ë¦¬ìƒë‹´ ì´ë¡  ì°¸ê³ :\n{reference}\n\n"
            f"ğŸ™‹ ë‚´ë‹´ì ê³ ë¯¼:\n{question}\n\nğŸ’¬ ìƒë‹´ì‚¬ ì‘ë‹µ:"
        )
        return self.get_llm_output(prompt)
