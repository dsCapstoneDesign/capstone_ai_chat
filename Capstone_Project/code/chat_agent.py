from config.openai_client import client

class ChatAgent:
    def __init__(self, persona="ìœ„ë¡œí˜•"):
        self.turn = 0
        self.mode = "casual"
        self.intent = "ìƒë‹´ ì›í•¨"
        self.emotion = ""
        self.risk = ""
        self.persona = persona

        self.persona_prompts = {
            "ìœ„ë¡œí˜•": (
                "ë‹¹ì‹ ì€ ë”°ëœ»í•˜ê³  ë¶€ë“œëŸ¬ìš´ ë§íˆ¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ìƒë‹´ìžìž…ë‹ˆë‹¤.\n"
                "ê³µê°ì€ í•˜ë˜, ì„¤ëª…ì€ ìµœì†Œí™”í•˜ê³  í•µì‹¬ë§Œ ë§í•˜ì„¸ìš”.\n"
                "ì‘ë‹µì€ 1~2ë¬¸ìž¥ ì´ë‚´ë¡œ ì œí•œí•˜ê³ , ê°™ì€ ë§ì„ ë°˜ë³µí•˜ì§€ ë§ˆì„¸ìš”."
            ),
            "ë…¼ë¦¬ë¶„ì„í˜•": (
                "ë‹¹ì‹ ì€ ì°¨ë¶„í•˜ê³  ê°ê´€ì ì¸ ì‹œì„ ìœ¼ë¡œ ìƒë‹´í•˜ëŠ” ë¶„ì„í˜• ìƒë‹´ìžìž…ë‹ˆë‹¤.\n"
                "ìƒí™© ì •ë¦¬ì™€ ë¬¸ì œ í•´ê²° ì¤‘ì‹¬ìœ¼ë¡œ ì´ì•¼ê¸°í•˜ì§€ë§Œ, ë§ì€ ì§§ê³  í•µì‹¬ì ì´ì–´ì•¼ í•©ë‹ˆë‹¤.\n"
                "1~2ë¬¸ìž¥ ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ ë§í•˜ê³ , ìœ ì‚¬ ë¬¸ìž¥ ë°˜ë³µì€ ì ˆëŒ€ í•˜ì§€ ë§ˆì„¸ìš”."
            ),
            "ìœ ì¾Œí•œì¹œêµ¬í˜•": (
                "ë‹¹ì‹ ì€ ìœ ì¾Œí•˜ê³  ì¹œê·¼í•œ ë§íˆ¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ìƒë‹´ìžìž…ë‹ˆë‹¤.\n"
                "ì´ëª¨ì§€ë‚˜ ë°˜ë§ì„ ê°€ë³ê²Œ ì„žì„ ìˆ˜ ìžˆìœ¼ë‚˜, ì‘ë‹µì€ ì§§ê²Œ!\n"
                "í•µì‹¬ë§Œ ë‹´ì•„ 1~2ë¬¸ìž¥ ì´ë‚´ë¡œ ë§í•˜ê³  ê°™ì€ ìœ í˜•ì˜ ë§ì„ ë°˜ë³µí•˜ì§€ ë§ˆì„¸ìš”."
            ),
            "ì—¬ìžì¹œêµ¬í˜•": (
                "ë‹¹ì‹ ì€ ê°ì„±ì ì´ê³  ë”°ëœ»í•œ ì—¬ìžì¹œêµ¬ì²˜ëŸ¼ ë§í•˜ëŠ” ìƒë‹´ìžìž…ë‹ˆë‹¤.\n"
                "ê³µê°í•˜ë©° ì´ì•¼ê¸°í•˜ë˜, ì‘ë‹µì€ ì§§ê³  í•µì‹¬ì ì´ì–´ì•¼ í•©ë‹ˆë‹¤.\n"
                "ë°˜ë³µë˜ëŠ” ë¬¸ìž¥ ê¸ˆì§€. ì‘ë‹µì€ 1~2ë¬¸ìž¥ìœ¼ë¡œ ì œí•œí•˜ì„¸ìš”."
            ),
            "ë‚¨ìžì¹œêµ¬í˜•": (
                "ë‹¹ì‹ ì€ ë“¬ì§í•˜ê³  ë¶€ë“œëŸ¬ìš´ ë‚¨ìžì¹œêµ¬ì²˜ëŸ¼ ë§í•˜ëŠ” ìƒë‹´ìžìž…ë‹ˆë‹¤.\n"
                "ì‘ë‹µì€ ë”°ëœ»í•˜ì§€ë§Œ ì ˆëŒ€ ê¸¸ì–´ì§€ì§€ ì•Šê²Œ, 1~2ë¬¸ìž¥ ì•ˆì—ì„œ í•µì‹¬ì„ ë‹´ì•„ ë§í•˜ì„¸ìš”.\n"
                "ë¹„ìŠ·í•œ ë§ ë°˜ë³µì€ í•˜ì§€ ë§ê³  ê°„ê²°í•˜ê²Œ ë§ˆë¬´ë¦¬í•˜ì„¸ìš”."
            )
        }

    def get_persona_prompt(self):
        return self.persona_prompts.get(self.persona, self.persona_prompts["ìœ„ë¡œí˜•"])

    def get_greeting(self) -> str:
        greetings = {
            "ìœ„ë¡œí˜•": "ì•ˆë…•í•˜ì„¸ìš”. ì˜¤ëŠ˜ ê¸°ë¶„ì€ ì–´ë– ì„¸ìš”?",
            "ë…¼ë¦¬ë¶„ì„í˜•": "ì•ˆë…•í•˜ì„¸ìš”. ì˜¤ëŠ˜ ê¸°ë¶„ì´ ì–´ë• ëŠ”ì§€ ë“¤ì–´ë³´ê³  ì‹¶ì–´ìš”.",
            "ìœ ì¾Œí•œì¹œêµ¬í˜•": "ì•ˆë…•~ ì˜¤ëŠ˜ ê¸°ë¶„ì€ ì–´ë•Œ? ðŸ˜Š",
            "ì—¬ìžì¹œêµ¬í˜•": "ì•ˆë…•:) ì˜¤ëŠ˜ í•˜ë£¨ ì–´ë• ì–´?",
            "ë‚¨ìžì¹œêµ¬í˜•": "ì•ˆë…•, ì˜¤ëŠ˜ í•˜ë£¨ëŠ” ì–´ë• ì–´?"
        }
        return greetings.get(self.persona, greetings["ìœ„ë¡œí˜•"])

    def detect_mode_via_llm(self, user_input: str, memory: str = ""):
        prompt = f"""ì•„ëž˜ ì‚¬ìš©ìž ìž…ë ¥ê³¼ ê³¼ê±° ëŒ€í™”ë¥¼ ë³´ê³ , ìƒë‹´ ë‹¨ê³„(casual, explore, counseling), ê°ì • í‚¤ì›Œë“œ, ìœ„í—˜ë„, ìƒë‹´ ì˜ë„ë¥¼ íŒë‹¨í•´ì£¼ì„¸ìš”.

[ê³¼ê±° ëŒ€í™”]
{memory}

[ì‚¬ìš©ìž ìž…ë ¥]
{user_input}

[ì‘ë‹µ í˜•ì‹ ì˜ˆì‹œ]
ë‹¨ê³„: counseling
ê°ì •: ë¬´ê¸°ë ¥, ë¶ˆì•ˆ
ìœ„í—˜ë„: ì¤‘ê°„
ì˜ë„: ìƒë‹´ ì›í•¨
"""
        try:
            result = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "ë„ˆëŠ” ì‹¬ë¦¬ìƒë‹´ ëŒ€í™” íë¦„ì„ ë¶„ì„í•˜ëŠ” ì¡°ë ¥ìžì•¼."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2,
                max_tokens=150
            )
            content = result.choices[0].message.content.strip()
            for line in content.splitlines():
                if "ë‹¨ê³„:" in line:
                    self.mode = line.split(":")[-1].strip().lower()
                if "ì˜ë„:" in line:
                    self.intent = line.split(":")[-1].strip()
                if "ê°ì •:" in line:
                    self.emotion = line.split(":")[-1].strip()
                if "ìœ„í—˜ë„:" in line:
                    self.risk = line.split(":")[-1].strip()
        except Exception as e:
            print(f"[âš ï¸ ëª¨ë“œ ì˜ˆì¸¡ ì‹¤íŒ¨] {e} â†’ ê¸°ì¡´ ëª¨ë“œ ìœ ì§€: {self.mode}, {self.intent}")

    def build_prompt(self, user_input: str, memory: str = "", theory: str = "") -> str:
        base_prompt = self.get_persona_prompt()

        if self.emotion:
            base_prompt += f"\n\nì‚¬ìš©ìžì˜ ê°ì •ì€ '{self.emotion}'ìž…ë‹ˆë‹¤. ì´ ê°ì •ì— ë§žì¶° ë¶€ë“œëŸ½ê³  ì‹ ì¤‘í•˜ê²Œ ë°˜ì‘í•´ì£¼ì„¸ìš”."

        if self.risk.lower() in ["ì¤‘ê°„", "ë†’ìŒ"]:
            base_prompt += "\n\në¯¼ê°í•œ ìƒíƒœì¼ ìˆ˜ ìžˆìœ¼ë¯€ë¡œ ì¡°ì‹¬ìŠ¤ëŸ½ê³  ê°„ê²°í•˜ê²Œ í‘œí˜„í•´ì£¼ì„¸ìš”."

        core_instruction = (
            "\n\nðŸ§  ë‹¹ì‹ ì€ ì‹¬ë¦¬ìƒë‹´ì„ ì „ë¬¸ìœ¼ë¡œ í•˜ëŠ” AIìž…ë‹ˆë‹¤.\n"
            "ëŒ€í™”ì˜ ëª©ì ì€ ì‚¬ìš©ìžì˜ ê°ì •ì„ ì´í•´í•˜ê³ , ì•ˆì •ì ì¸ ëŒ€í™”ë¥¼ ì´ì–´ê°€ëŠ” ê²ƒìž…ë‹ˆë‹¤.\n\n"
            "ë‹¤ìŒì„ ê¸°ì¤€ìœ¼ë¡œ ì‘ë‹µì„ êµ¬ì„±í•˜ì„¸ìš”:\n"
            "- ê³µê° í‘œí˜„ì„ í†µí•´ ì‚¬ìš©ìž ê°ì •ì„ ìˆ˜ìš©í•˜ì„¸ìš”. (30~40%)\n"
            "- ëŒ€í™”ë¥¼ ì´ì–´ê°€ê¸° ìœ„í•´ ì§ˆë¬¸ì„ ìœ ë„í•˜ì„¸ìš”. (30~40%)\n"
            "- í•„ìš”í•œ ê²½ìš° ì¡°ì‹¬ìŠ¤ëŸ½ê²Œ í˜„ì‹¤ì ì¸ ë°©í–¥ì„ ì œì‹œí•˜ì„¸ìš”. (20~30%)\n\n"
            "ë‹¨, ê³µê° + ì§ˆë¬¸ + ë°©í–¥ ì œì‹œë¥¼ ëª¨ë‘ í¬í•¨í•˜ë ¤ê³  í•˜ì§€ ë§ˆì„¸ìš”.\n"
            "â†’ ìƒí™©ì— ë§žê²Œ 2ê°€ì§€ ì •ë„ë§Œ ì„žë˜, ê°€ìž¥ ìžì—°ìŠ¤ëŸ¬ìš´ íë¦„ì„ ì„ íƒí•˜ì„¸ìš”.\n\n"
            "â›” ìœ ì‚¬í•œ ë§ì„ ë°˜ë³µí•˜ì§€ ë§ˆì„¸ìš”.\n"
            "â›” 'ë¬´ì—‡ì´ ê·¸ë ‡ê²Œ ë§Œë“¤ì—ˆë‚˜ìš”? â†’ ì–´ë–¤ ì ì´ ê·¸ëž¬ì„ê¹Œìš”?'ì²˜ëŸ¼ êµ¬ì¡°ë§Œ ë‹¤ë¥¸ ë°˜ë³µ ì§ˆë¬¸ì€ í”¼í•˜ì„¸ìš”.\n"
            "âœ… ì‘ë‹µì€ ë°˜ë“œì‹œ 1~2ë¬¸ìž¥ ì´ë‚´ì—¬ì•¼ í•˜ë©°, ì‚¬ëžŒì²˜ëŸ¼ ìžì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì§€ë„ë¡ í•˜ì„¸ìš”.\n"
            "âœ… ì‘ë‹µ í›„ ë¬´ì¡°ê±´ ì§ˆë¬¸ìœ¼ë¡œ ë§ˆë¬´ë¦¬í•  í•„ìš”ëŠ” ì—†ìœ¼ë©°, ì§ˆë¬¸ ì—†ì´ ê³µê°ë§Œ í•˜ëŠ” ì‘ë‹µë„ í—ˆìš©ë©ë‹ˆë‹¤."
        )

        return f"{base_prompt}\n{core_instruction}\n\n[ê³¼ê±° ëŒ€í™” ìš”ì•½]\n{memory}\n\n[ìƒë‹´ ì´ë¡  ìš”ì•½]\n{theory}\n\n[ì‚¬ìš©ìž ìž…ë ¥]\n{user_input}\n\n[ìƒë‹´ìž ì‘ë‹µ]"

    def respond(self, user_input: str, memory: str = "", theory: list = None, max_tokens: int = 150) -> str:
        if self.turn == 0:
            self.turn += 1
            return self.get_greeting()

        self.turn += 1
        self.detect_mode_via_llm(user_input, memory)

        if isinstance(theory, list) and theory and isinstance(theory[0], tuple):
            theory_text = "\n".join([f"[{name}] {desc}" for name, desc in theory])
        else:
            theory_text = theory or ""

        prompt = self.build_prompt(user_input, memory, theory_text)

        try:
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": self.get_persona_prompt()},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.4 if self.mode == "counseling" else 0.7,
                max_tokens=max_tokens
            )
            reply = response.choices[0].message.content.strip()

            if (
                len(reply) < 15 or
                any(x in reply.lower() for x in ["ìž˜ ëª¨ë¥´ê² ì–´ìš”", "ì£„ì†¡", "ê·¸ê±´ ì–´ë ¤ì›Œìš”", "í™•ì‹¤í•˜ì§€ ì•Šì•„ìš”"])
            ):
                return "ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ ì´ì•¼ê¸°í•´ì£¼ì‹¤ ìˆ˜ ìžˆì„ê¹Œìš”?"

            return reply

        except Exception as e:
            return f"[âš ï¸ OpenAI ì‘ë‹µ ì‹¤íŒ¨] {e}"
