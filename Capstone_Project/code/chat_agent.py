from config.openai_client import client

class ChatAgent:
    def __init__(self, persona="ìœ„ë¡œí˜•"):
        self.turn = 0
        self.mode = "casual"
        self.intent = "ìƒë‹´ ì›í•¨"
        self.emotion = ""
        self.risk = ""
        self.persona = persona

        self.persona_prompts = {
            "ìœ„ë¡œí˜•": (
                "ë‹¹ì‹ ì€ ë”°ëœ»í•˜ê³  ë¶€ë“œëŸ¬ìš´ ë§íˆ¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ìƒë‹´ìžìž…ë‹ˆë‹¤.\n"
                "ì—„ë§ˆì²˜ëŸ¼ í¬ê·¼í•˜ê²Œ ì‚¬ìš©ìžì˜ ê°ì •ì„ ê°ì‹¸ì¤ë‹ˆë‹¤.\n"
                "ê³µê°ì€ í•˜ë˜, ì„¤ëª…ì€ ìµœì†Œí™”í•˜ê³  í•µì‹¬ë§Œ ë§í•˜ì„¸ìš”.\n"
                "ì‘ë‹µì€ 1~2ë¬¸ìž¥ ì´ë‚´ë¡œ ì œí•œí•˜ê³ , ê°™ì€ ë§ì„ ë°˜ë³µí•˜ì§€ ë§ˆì„¸ìš”."
            ),
            "ë…¼ë¦¬ë¶„ì„í˜•": (
                "ë‹¹ì‹ ì€ ì°¨ë¶„í•˜ê³  ê°ê´€ì ì¸ ì‹œì„ ìœ¼ë¡œ ìƒë‹´í•˜ëŠ” ë¶„ì„í˜• ìƒë‹´ìžìž…ë‹ˆë‹¤.\n"
                "ìƒí™© ì •ë¦¬ì™€ ë¬¸ì œ í•´ê²° ì¤‘ì‹¬ìœ¼ë¡œ ì´ì•¼ê¸°í•˜ì§€ë§Œ, ë§ì€ ì§§ê³  í•µì‹¬ì ì´ì–´ì•¼ í•©ë‹ˆë‹¤.\n"
                "1~2ë¬¸ìž¥ ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ ë§í•˜ê³ , ìœ ì‚¬ ë¬¸ìž¥ ë°˜ë³µì€ ì ˆëŒ€ í•˜ì§€ ë§ˆì„¸ìš”."
            ),
            "ìœ ì¾Œí•œì¹œêµ¬í˜•": (
                "ë‹¹ì‹ ì€ ìœ ì¾Œí•˜ê³  ì¹œê·¼í•œ ë§íˆ¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ìƒë‹´ìžìž…ë‹ˆë‹¤.\n"
                "ì´ëª¨ì§€ë‚˜ ë°˜ë§ì„ ê°€ë³ê²Œ ì„žì„ ìˆ˜ ìžˆìœ¼ë‚˜, ì‘ë‹µì€ ì§§ê²Œ!\n"
                "í•µì‹¬ë§Œ ë‹´ì•„ 1~2ë¬¸ìž¥ ì´ë‚´ë¡œ ë§í•˜ê³  ê°™ì€ ìœ í˜•ì˜ ë§ì„ ë°˜ë³µí•˜ì§€ ë§ˆì„¸ìš”."
            ),
            "ì—¬ìžì¹œêµ¬í˜•": (
                "ë‹¹ì‹ ì€ ê°ì„±ì ì´ê³  ë”°ëœ»í•œ ì—¬ìžì¹œêµ¬ì²˜ëŸ¼ ë§í•˜ëŠ” ìƒë‹´ìžìž…ë‹ˆë‹¤.\n"
                "ê³µê°í•˜ë©° ì´ì•¼ê¸°í•˜ë˜, ì‘ë‹µì€ ì§§ê³  í•µì‹¬ì ì´ì–´ì•¼ í•©ë‹ˆë‹¤.\n"
                "ë°˜ë³µë˜ëŠ” ë¬¸ìž¥ ê¸ˆì§€. ì‘ë‹µì€ 1~2ë¬¸ìž¥ìœ¼ë¡œ ì œí•œí•˜ì„¸ìš”."
            ),
            "ë‚¨ìžì¹œêµ¬í˜•": (
                "ë‹¹ì‹ ì€ ë“¬ì§í•˜ê³  ë¶€ë“œëŸ¬ìš´ ë‚¨ìžì¹œêµ¬ì²˜ëŸ¼ ë§í•˜ëŠ” ìƒë‹´ìžìž…ë‹ˆë‹¤.\n"
                "ì‘ë‹µì€ ë”°ëœ»í•˜ì§€ë§Œ ì ˆëŒ€ ê¸¸ì–´ì§€ì§€ ì•Šê²Œ, 1~2ë¬¸ìž¥ ì•ˆì—ì„œ í•µì‹¬ì„ ë‹´ì•„ ë§í•˜ì„¸ìš”.\n"
                "ë¹„ìŠ·í•œ ë§ ë°˜ë³µì€ í•˜ì§€ ë§ê³  ê°„ê²°í•˜ê²Œ ë§ˆë¬´ë¦¬í•˜ì„¸ìš”."
            )
        }

    def get_persona_prompt(self):
        return self.persona_prompts.get(self.persona, self.persona_prompts["ìœ„ë¡œí˜•"])

    def detect_mode_via_llm(self, user_input: str, memory: str = ""):
        prompt = f"""ì•„ëž˜ ì‚¬ìš©ìž ìž…ë ¥ê³¼ ê³¼ê±° ëŒ€í™”ë¥¼ ë³´ê³ , ìƒë‹´ ë‹¨ê³„(casual, explore, counseling), ê°ì • í‚¤ì›Œë“œ, ìœ„í—˜ë„, ìƒë‹´ ì˜ë„ë¥¼ íŒë‹¨í•´ì£¼ì„¸ìš”.

[ê³¼ê±° ëŒ€í™”]
{memory}

[ì‚¬ìš©ìž ìž…ë ¥]
{user_input}

[ì‘ë‹µ í˜•ì‹ ì˜ˆì‹œ]
ë‹¨ê³„: counseling
ê°ì •: ë¬´ê¸°ë ¥, ë¶ˆì•ˆ
ìœ„í—˜ë„: ì¤‘ê°„
ì˜ë„: ìƒë‹´ ì›í•¨
"""
        try:
            result = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "ë„ˆëŠ” ì‹¬ë¦¬ìƒë‹´ ëŒ€í™” íë¦„ì„ ë¶„ì„í•˜ëŠ” ì¡°ë ¥ìžì•¼."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2,
                max_tokens=150
            )
            content = result.choices[0].message.content.strip()
            for line in content.splitlines():
                if "ë‹¨ê³„:" in line:
                    self.mode = line.split(":")[-1].strip().lower()
                if "ì˜ë„:" in line:
                    self.intent = line.split(":")[-1].strip()
                if "ê°ì •:" in line:
                    self.emotion = line.split(":")[-1].strip()
                if "ìœ„í—˜ë„:" in line:
                    self.risk = line.split(":")[-1].strip()
        except Exception as e:
            print(f"[âš ï¸ ëª¨ë“œ ì˜ˆì¸¡ ì‹¤íŒ¨] {e} â†’ ê¸°ì¡´ ëª¨ë“œ ìœ ì§€: {self.mode}, {self.intent}")

    def build_prompt(self, user_input: str, memory: str = "", theory: str = "") -> str:
        base_prompt = self.get_persona_prompt()

        if self.emotion:
            base_prompt += f"\n\nì‚¬ìš©ìžì˜ ê°ì •ì€ '{self.emotion}'ìž…ë‹ˆë‹¤. ì´ ê°ì •ì— ê³µê°í•˜ë˜, ë°˜ë³µ ì—†ì´ 1~2ë¬¸ìž¥ìœ¼ë¡œ ë°˜ì‘í•˜ì„¸ìš”."
        if self.risk.lower() in ["ì¤‘ê°„", "ë†’ìŒ"]:
            base_prompt += "\n\në¯¼ê°í•œ ìƒíƒœì¼ ìˆ˜ ìžˆìœ¼ë¯€ë¡œ ë”°ëœ»í•˜ì§€ë§Œ ì§§ê³  ì‹ ì¤‘í•˜ê²Œ ë§í•´ì£¼ì„¸ìš”."

        if memory and self.turn == 0:
            base_prompt += f"\n\nì´ì „ ëŒ€í™” ë‚´ìš©ì´ ìžˆìŠµë‹ˆë‹¤:\n{memory}\n\nðŸ‘‰ ì²« ì‘ë‹µì€ íŠ¹ížˆ ì§§ê³  ë‹¨ì •ì ìœ¼ë¡œ ì‹œìž‘í•´ì£¼ì„¸ìš”. ê³µê°ì€ 1ë¬¸ìž¥ìœ¼ë¡œ, ì§ˆë¬¸ì€ ê°„ê²°í•˜ê²Œ í•˜ì„¸ìš”."

        if self.turn >= 3:
            base_prompt += "\n\nì§€ê¸ˆì€ ìƒë‹´ì´ ì–´ëŠ ì •ë„ ì§„í–‰ëœ ìƒíƒœìž…ë‹ˆë‹¤. ì‹¤ì²œ ì „ëžµì´ í•„ìš”í•˜ë©´ í•µì‹¬ë§Œ 1~2ë¬¸ìž¥ìœ¼ë¡œ ì œì‹œí•˜ì„¸ìš”."

        theory_instruction = ""
        if self.intent == "ìƒë‹´ ì›í•¨" and theory:
            theory_instruction = (
                "\n\nìƒë‹´ ì´ë¡ ì„ ì„¤ëª…í•˜ì§€ ë§ê³ , í•µì‹¬ ê°œë…ë§Œ ì‚¬ìš©ìž ìƒí™©ì— ì§§ê²Œ ì ìš©í•´ì£¼ì„¸ìš”. ë§ì€ 2ë¬¸ìž¥ ì´ë‚´ë¡œ!"
            )

        closing_instruction = "\n\nâ›” ì ˆëŒ€ ìœ ì‚¬ í‘œí˜„ ë°˜ë³µí•˜ì§€ ë§ˆì„¸ìš”. ì‘ë‹µì€ ë°˜ë“œì‹œ 1~2ë¬¸ìž¥ìœ¼ë¡œ ì œí•œí•˜ê³ , ì§ˆë¬¸ì€ í•œ ë¬¸ìž¥ë§Œ ë§ë¶™ì´ì„¸ìš”."

        return f"""{base_prompt}{theory_instruction}{closing_instruction}

[ê³¼ê±° ëŒ€í™” ìš”ì•½]
{memory}

[ìƒë‹´ ì´ë¡  ìš”ì•½]
{theory}

[ì‚¬ìš©ìž ìž…ë ¥]
{user_input}

[ìƒë‹´ìž ì‘ë‹µ]
""".strip()

    def respond(self, user_input: str, memory: str = "", theory: list = None, max_tokens: int = 150) -> str:
        self.turn += 1
        self.detect_mode_via_llm(user_input, memory)

        if isinstance(theory, list) and theory and isinstance(theory[0], tuple):
            theory_text = "\n".join([f"[{name}] {desc}" for name, desc in theory])
        else:
            theory_text = theory or ""

        prompt = self.build_prompt(user_input, memory, theory_text)

        try:
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": self.get_persona_prompt()},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.4 if self.mode == "counseling" else 0.7,
                max_tokens=max_tokens
            )
            reply = response.choices[0].message.content.strip()

            if (
                len(reply) < 15 or
                any(x in reply.lower() for x in ["ìž˜ ëª¨ë¥´ê² ì–´ìš”", "ì£„ì†¡", "ê·¸ê±´ ì–´ë ¤ì›Œìš”", "í™•ì‹¤í•˜ì§€ ì•Šì•„ìš”"])
            ):
                return "ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ ì´ì•¼ê¸°í•´ì£¼ì‹¤ ìˆ˜ ìžˆì„ê¹Œìš”?"

            return reply

        except Exception as e:
            return f"[âš ï¸ OpenAI ì‘ë‹µ ì‹¤íŒ¨] {e}"
