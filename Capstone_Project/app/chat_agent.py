from .config.openai_client import client

with open("debug_log.txt", "a") as f:
    f.write("âœ… chat_agent.pyê°€ FastAPIì— ë¡œë”©ë˜ì—ˆìŠµë‹ˆë‹¤!\n")

class ChatAgent:
    def __init__(self, persona="ìœ„ë¡œí˜•"):
        self.mode = "casual"
        self.intent = "ìƒë‹´ ì›í•¨"
        self.emotion = ""
        self.risk = ""
        self.persona = persona

        self.persona_prompts = {
            "ìœ„ë¡œí˜•": (
                "ë‹¹ì‹ ì€ ë”°ëœ»í•˜ê³  ë¶€ë“œëŸ¬ìš´ ë§íˆ¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ìƒë‹´ìì…ë‹ˆë‹¤.\n"
                "ê³µê°ì€ í•˜ë˜, ì„¤ëª…ì€ ìµœì†Œí™”í•˜ê³  í•µì‹¬ë§Œ ë§í•˜ì„¸ìš”.\n"
                "ì‘ë‹µì€ 1~2ë¬¸ì¥ ì´ë‚´ë¡œ ì œí•œí•˜ê³ , ê°™ì€ ë§ì„ ë°˜ë³µí•˜ì§€ ë§ˆì„¸ìš”."
            ),
            "ë…¼ë¦¬ë¶„ì„í˜•": (
                "ë‹¹ì‹ ì€ ì°¨ë¶„í•˜ê³  ê°ê´€ì ì¸ ì‹œì„ ìœ¼ë¡œ ìƒë‹´í•˜ëŠ” ë¶„ì„í˜• ìƒë‹´ìì…ë‹ˆë‹¤.\n"
                "ìƒí™© ì •ë¦¬ì™€ ë¬¸ì œ í•´ê²° ì¤‘ì‹¬ìœ¼ë¡œ ì´ì•¼ê¸°í•˜ì§€ë§Œ, ë§ì€ ì§§ê³  í•µì‹¬ì ì´ì–´ì•¼ í•©ë‹ˆë‹¤.\n"
                "1~2ë¬¸ì¥ ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ ë§í•˜ê³ , ìœ ì‚¬ ë¬¸ì¥ ë°˜ë³µì€ ì ˆëŒ€ í•˜ì§€ ë§ˆì„¸ìš”."
            ),
            "ìœ ì¾Œí•œì¹œêµ¬í˜•": (
                "ë‹¹ì‹ ì€ ìœ ì¾Œí•˜ê³  ì¹œê·¼í•œ ë§íˆ¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ìƒë‹´ìì…ë‹ˆë‹¤.\n"
                "ì´ëª¨ì§€ë‚˜ ë°˜ë§ì„ ê°€ë³ê²Œ ì„ì„ ìˆ˜ ìˆìœ¼ë‚˜, ì‘ë‹µì€ ì§§ê²Œ!\n"
                "í•µì‹¬ë§Œ ë‹´ì•„ 1~2ë¬¸ì¥ ì´ë‚´ë¡œ ë§í•˜ê³  ê°™ì€ ìœ í˜•ì˜ ë§ì„ ë°˜ë³µí•˜ì§€ ë§ˆì„¸ìš”."
            ),
            "ì—¬ìì¹œêµ¬í˜•": (
                "ë‹¹ì‹ ì€ ê°ì„±ì ì´ê³  ë”°ëœ»í•œ ì—¬ìì¹œêµ¬ì²˜ëŸ¼ ë§í•˜ëŠ” ìƒë‹´ìì…ë‹ˆë‹¤.\n"
                "ê³µê°í•˜ë©° ì´ì•¼ê¸°í•˜ë˜, ì‘ë‹µì€ ì§§ê³  í•µì‹¬ì ì´ì–´ì•¼ í•©ë‹ˆë‹¤.\n"
                "ë°˜ë³µë˜ëŠ” ë¬¸ì¥ ê¸ˆì§€. ì‘ë‹µì€ 1~2ë¬¸ì¥ìœ¼ë¡œ ì œí•œí•˜ì„¸ìš”."
            ),
            "ë‚¨ìì¹œêµ¬í˜•": (
                "ë‹¹ì‹ ì€ ë“¬ì§í•˜ê³  ë¶€ë“œëŸ¬ìš´ ë‚¨ìì¹œêµ¬ì²˜ëŸ¼ ë§í•˜ëŠ” ìƒë‹´ìì…ë‹ˆë‹¤.\n"
                "ì‘ë‹µì€ ë”°ëœ»í•˜ì§€ë§Œ ì ˆëŒ€ ê¸¸ì–´ì§€ì§€ ì•Šê²Œ, 1~2ë¬¸ì¥ ì•ˆì—ì„œ í•µì‹¬ì„ ë‹´ì•„ ë§í•˜ì„¸ìš”.\n"
                "ë¹„ìŠ·í•œ ë§ ë°˜ë³µì€ í•˜ì§€ ë§ê³  ê°„ê²°í•˜ê²Œ ë§ˆë¬´ë¦¬í•˜ì„¸ìš”."
            )
        }

    def get_persona_prompt(self):
        return self.persona_prompts.get(self.persona, self.persona_prompts["ìœ„ë¡œí˜•"])

    def detect_mode_via_llm(self, user_input: str, memory: str = ""):
        prompt = f"""ì•„ë˜ ì‚¬ìš©ì ì…ë ¥ê³¼ ê³¼ê±° ëŒ€í™”ë¥¼ ë³´ê³ , ìƒë‹´ ë‹¨ê³„(casual, explore, counseling), ê°ì • í‚¤ì›Œë“œ, ìœ„í—˜ë„, ìƒë‹´ ì˜ë„ë¥¼ íŒë‹¨í•´ì£¼ì„¸ìš”.

[ê³¼ê±° ëŒ€í™”]
{memory}

[ì‚¬ìš©ì ì…ë ¥]
{user_input}

[ì‘ë‹µ í˜•ì‹ ì˜ˆì‹œ]
ë‹¨ê³„: counseling
ê°ì •: ë¬´ê¸°ë ¥, ë¶ˆì•ˆ
ìœ„í—˜ë„: ì¤‘ê°„
ì˜ë„: ìƒë‹´ ì›í•¨
"""
        try:
            result = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "ë„ˆëŠ” ì‹¬ë¦¬ìƒë‹´ ëŒ€í™” íë¦„ì„ ë¶„ì„í•˜ëŠ” ì¡°ë ¥ìì•¼."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2,
                max_tokens=150
            )
            content = result.choices[0].message.content.strip()
            for line in content.splitlines():
                if "ë‹¨ê³„:" in line:
                    self.mode = line.split(":")[-1].strip().lower()
                elif "ì˜ë„:" in line:
                    self.intent = line.split(":")[-1].strip()
                elif "ê°ì •:" in line:
                    self.emotion = line.split(":")[-1].strip()
                elif "ìœ„í—˜ë„:" in line:
                    self.risk = line.split(":")[-1].strip()

            with open("debug_log.txt", "a") as f:
                f.write(f"ğŸ” ê°ì • ë¶„ì„ ê²°ê³¼ - mode: {self.mode}, emotion: {self.emotion}, risk: {self.risk}\n")

        except Exception as e:
            with open("debug_log.txt", "a") as f:
                f.write(f"[âš ï¸ ëª¨ë“œ ì˜ˆì¸¡ ì‹¤íŒ¨] {e}\n")

    def build_prompt(self, user_input: str, memory: str = "", theory: str = "") -> str:
        base_prompt = self.get_persona_prompt()

        if self.emotion:
            base_prompt += f"\n\nì‚¬ìš©ìì˜ ê°ì •ì€ '{self.emotion}'ì…ë‹ˆë‹¤. ì´ ê°ì •ì— ë§ì¶° ë¶€ë“œëŸ½ê³  ì‹ ì¤‘í•˜ê²Œ ë°˜ì‘í•´ì£¼ì„¸ìš”."

        if self.risk.lower() in ["ì¤‘ê°„", "ë†’ìŒ"]:
            base_prompt += "\n\në¯¼ê°í•œ ìƒíƒœì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì¡°ì‹¬ìŠ¤ëŸ½ê³  ê°„ê²°í•˜ê²Œ í‘œí˜„í•´ì£¼ì„¸ìš”."

        core_instruction = (
            "\n\nğŸ§  ë‹¹ì‹ ì€ ì‹¬ë¦¬ìƒë‹´ì„ ì „ë¬¸ìœ¼ë¡œ í•˜ëŠ” AIì…ë‹ˆë‹¤.\n"
            "ëŒ€í™”ì˜ ëª©ì ì€ ì‚¬ìš©ìì˜ ê°ì •ì„ ì´í•´í•˜ê³ , ì•ˆì •ì ì¸ ëŒ€í™”ë¥¼ ì´ì–´ê°€ëŠ” ê²ƒì…ë‹ˆë‹¤.\n\n"
            "ë‹¤ìŒì„ ê¸°ì¤€ìœ¼ë¡œ ì‘ë‹µì„ êµ¬ì„±í•˜ì„¸ìš”:\n"
            "- ê³µê° í‘œí˜„ì„ í†µí•´ ì‚¬ìš©ì ê°ì •ì„ ìˆ˜ìš©í•˜ì„¸ìš”. (25%)\n"
            "- ëŒ€í™”ë¥¼ ì´ì–´ê°€ê¸° ìœ„í•´ ì§ˆë¬¸ì„ ìœ ë„í•˜ì„¸ìš”. (30%)\n"
            "- í•„ìš”í•œ ê²½ìš° ì¡°ì‹¬ìŠ¤ëŸ½ê²Œ í˜„ì‹¤ì ì¸ ë°©í–¥ì„ ì œì‹œí•˜ì„¸ìš”. (20%)\n"
            "- í•„ìš”í•œ ê²½ìš° ì‹¬ë¦¬ìƒë‹´ì´ë¡ ì„ ê¸°ë°˜ìœ¼ë¡œ ëŒ€í™”ë¥¼ ì´ì–´ë‚˜ê°€ì„¸ìš” (20%)\n\n"
            "ë‹¨, ê³µê° + ì§ˆë¬¸ + ë°©í–¥ ì œì‹œë¥¼ ëª¨ë‘ í¬í•¨í•˜ë ¤ê³  í•˜ì§€ ë§ˆì„¸ìš”.\n"
            "â†’ ìƒí™©ì— ë§ê²Œ 2ê°€ì§€ ì •ë„ë§Œ ì„ë˜, ê°€ì¥ ìì—°ìŠ¤ëŸ¬ìš´ íë¦„ì„ ì„ íƒí•˜ì„¸ìš”.\n\n"
            "âœ… ìœ ì‚¬í•œ ë¬¸ì¥ ë°˜ë³µ ê¸ˆì§€\n"
            "âœ… ë°˜ë“œì‹œ 1~2ë¬¸ì¥ ì´ë‚´ë¡œ ë‹µë³€í•  ê²ƒ"
        )

        return f"{base_prompt}\n{core_instruction}\n\n[ê³¼ê±° ëŒ€í™” ìš”ì•½]\n{memory}\n\n[ìƒë‹´ ì´ë¡  ìš”ì•½]\n{theory}\n\n[ì‚¬ìš©ì ì…ë ¥]\n{user_input}\n\n[ìƒë‹´ì ì‘ë‹µ]"

    def respond(self, user_input: str, memory: str = "", theory: list = None, max_tokens: int = 150) -> str:
        with open("debug_log.txt", "a") as f:
            f.write(f"\nğŸ§© respond ì§„ì… | user_input: {user_input}\n")

        self.detect_mode_via_llm(user_input, memory)

        theory_text = "\n".join([f"[{name}] {desc}" for name, desc in theory]) if isinstance(theory, list) else theory or ""
        system_prompt = self.build_prompt(user_input, memory, theory_text)

        with open("debug_log.txt", "a") as f:
            f.write("ğŸ§  build_prompt ì™„ë£Œ. GPT í˜¸ì¶œ ì‹œì‘...\n")

        try:
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_input}
                ],
                temperature=0.4 if self.mode == "counseling" else 0.7,
                max_tokens=max_tokens
            )
            reply = response.choices[0].message.content.strip()

            with open("debug_log.txt", "a") as f:
                f.write(f"âœ… GPT ì‘ë‹µ ìˆ˜ì‹ : {reply}\n")

            if (
                len(reply) < 15 or
                any(x in reply.lower() for x in ["ì˜ ëª¨ë¥´ê² ì–´ìš”", "ì£„ì†¡", "ì–´ë ¤ì›Œìš”", "í™•ì‹¤í•˜ì§€ ì•Šì•„ìš”"])
            ):
                with open("debug_log.txt", "a") as f:
                    f.write("ğŸ§© ì‘ë‹µ í’ˆì§ˆ ë‚®ìŒ - fallback ë¬¸êµ¬ ë°˜í™˜\n")
                return "ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ ì´ì•¼ê¸°í•´ì£¼ì‹¤ ìˆ˜ ìˆì„ê¹Œìš”?"

            return reply

        except Exception as e:
            with open("debug_log.txt", "a") as f:
                f.write(f"âš ï¸ GPT í˜¸ì¶œ ì‹¤íŒ¨: {e}\n")
            return "ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ ì´ì•¼ê¸°í•´ì£¼ì‹¤ ìˆ˜ ìˆì„ê¹Œìš”?"
