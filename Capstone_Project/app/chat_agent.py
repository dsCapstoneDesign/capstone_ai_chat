from app.config.openai_client import client
from app.memory_manager import summarize_memory, load_user_memory, is_first_entry

with open("debug_log.txt", "a") as f:
    f.write("âœ… chat_agent.pyê°€ FastAPIì— ë¡œë”©ë˜ì—ˆìŠµë‹ˆë‹¤!\n")

class ChatAgent:
    def __init__(self, persona="ìœ„ë¡œí˜•"):
        self.mode = "casual"
        self.intent = "ìƒë‹´ ì›í•¨"
        self.emotion = ""
        self.risk = ""
        self.persona = persona

        self.persona_prompts = {
            "ìœ„ë¡œí˜•": (
                "[í˜ë¥´ì†Œë‚˜: ìœ„ë¡œí˜•]\n"
                "ë‹¹ì‹ ì€ ë”°ëœ»í•˜ê³  ë¶€ë“œëŸ¬ìš´ ë§íˆ¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ìƒë‹´ìì…ë‹ˆë‹¤.\n"
                "ê³µê°ì€ í•˜ë˜, ì„¤ëª…ì€ ìµœì†Œí™”í•˜ê³  í•µì‹¬ë§Œ ë§í•˜ì„¸ìš”.\n"
                "ì‘ë‹µì€ 1~2ë¬¸ì¥ ì´ë‚´ë¡œ ì œí•œí•˜ê³ , ê°™ì€ ë§ì„ ë°˜ë³µí•˜ì§€ ë§ˆì„¸ìš”."
            ),
            "ë…¼ë¦¬í˜•": (
                "[í˜ë¥´ì†Œë‚˜: ë…¼ë¦¬í˜•]\n"
                "ë‹¹ì‹ ì€ ì°¨ë¶„í•˜ê³  ê°ê´€ì ì¸ ì‹œì„ ìœ¼ë¡œ ìƒë‹´í•˜ëŠ” ë¶„ì„í˜• ìƒë‹´ìì…ë‹ˆë‹¤.\n"
                "ìƒí™© ì •ë¦¬ì™€ ë¬¸ì œ í•´ê²° ì¤‘ì‹¬ìœ¼ë¡œ ì´ì•¼ê¸°í•˜ì§€ë§Œ, ë§ì€ ì§§ê³  í•µì‹¬ì ì´ì–´ì•¼ í•©ë‹ˆë‹¤.\n"
                "1~2ë¬¸ì¥ ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ ë§í•˜ê³ , ìœ ì‚¬ ë¬¸ì¥ ë°˜ë³µì€ ì ˆëŒ€ í•˜ì§€ ë§ˆì„¸ìš”."
            ),
            "ê¸ì •í˜•": (
                "[í˜ë¥´ì†Œë‚˜: ê¸ì •í˜•]\n"
                "ë‹¹ì‹ ì€ ìœ ì¾Œí•˜ê³  ê¸ì •ì ì¸ ë§íˆ¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ìƒë‹´ìì…ë‹ˆë‹¤.\n"
                "ì¹œê·¼í•˜ê³  ëª…ë‘í•œ ë§íˆ¬ë¡œ ì§§ê²Œ ë°˜ì‘í•˜ë˜, í•µì‹¬ì„ ë†“ì¹˜ì§€ ë§ˆì„¸ìš”.\n"
                "ì‘ë‹µì€ 1~2ë¬¸ì¥ ì´ë‚´ë¡œ ì œí•œí•˜ê³ , ê°™ì€ ìœ í˜•ì˜ ë§ì„ ë°˜ë³µí•˜ì§€ ë§ˆì„¸ìš”."
            )
        }

    def get_persona_prompt(self):
        return self.persona_prompts.get(self.persona, self.persona_prompts["ìœ„ë¡œí˜•"])

    def detect_mode_via_llm(self, user_input: str, memory: str = ""):
        prompt = f"""ì•„ë˜ ì‚¬ìš©ì ì…ë ¥ê³¼ ê³¼ê±° ëŒ€í™”ë¥¼ ë³´ê³ , ìƒë‹´ ë‹¨ê³„(casual, explore, counseling), ê°ì • í‚¤ì›Œë“œ, ìœ„í—˜ë„, ìƒë‹´ ì˜ë„ë¥¼ íŒë‹¨í•´ì£¼ì„¸ìš”.

[ê³¼ê±° ëŒ€í™”]
{memory}

[ì‚¬ìš©ì ì…ë ¥]
{user_input}

[ì‘ë‹µ í˜•ì‹ ì˜ˆì‹œ]
ë‹¨ê³„: counseling
ê°ì •: ë¬´ê¸°ë ¥, ë¶ˆì•ˆ
ìœ„í—˜ë„: ì¤‘ê°„
ì˜ë„: ìƒë‹´ ì›í•¨
"""
        try:
            result = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ë„ˆëŠ” ì‹¬ë¦¬ìƒë‹´ ëŒ€í™” íë¦„ì„ ë¶„ì„í•˜ëŠ” ì¡°ë ¥ìì•¼."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2,
                max_tokens=150
            )
            content = result.choices[0].message.content.strip()
            for line in content.splitlines():
                if "ë‹¨ê³„:" in line:
                    self.mode = line.split(":")[-1].strip().lower()
                elif "ì˜ë„:" in line:
                    self.intent = line.split(":")[-1].strip()
                elif "ê°ì •:" in line:
                    self.emotion = line.split(":")[-1].strip()
                elif "ìœ„í—˜ë„:" in line:
                    self.risk = line.split(":")[-1].strip()

            with open("debug_log.txt", "a") as f:
                f.write(f"ğŸ” ê°ì • ë¶„ì„ ê²°ê³¼ - mode: {self.mode}, emotion: {self.emotion}, risk: {self.risk}\n")

        except Exception as e:
            with open("debug_log.txt", "a") as f:
                f.write(f"[âš ï¸ ëª¨ë“œ ì˜ˆì¸¡ ì‹¤íŒ¨] {e}\n")

    def build_prompt(self, user_input: str, memory: str = "", theory: str = "") -> str:
        base_prompt = self.get_persona_prompt()

        if self.emotion:
            base_prompt += f"\n\n[í˜„ì¬ ê°ì • ìƒíƒœ]\nì‚¬ìš©ìëŠ” '{self.emotion}'ë¼ëŠ” ê°ì •ì„ í‘œí˜„í–ˆìŠµë‹ˆë‹¤."

        if self.risk.lower() in ["ì¤‘ê°„", "ë†’ìŒ"]:
            base_prompt += "\nìœ„í—˜ë„ê°€ ë†’ìœ¼ë¯€ë¡œ ì¡°ì‹¬ìŠ¤ëŸ½ê³  ê°„ê²°í•˜ê²Œ í‘œí˜„í•´ì£¼ì„¸ìš”."

        core_instruction = (
            "\n\nğŸ§  ë‹¹ì‹ ì€ ì‹¬ë¦¬ìƒë‹´ì„ ì „ë¬¸ìœ¼ë¡œ í•˜ëŠ” AI ìƒë‹´ìì…ë‹ˆë‹¤.\n"
            "ì‚¬ìš©ìì™€ ëŒ€í™”ë¥¼ ì´ì–´ê°€ë©° ê°ì •ì„ ì´í•´í•˜ê³  ê³µê°í•˜ì„¸ìš”.\n"
            "ê° ìƒí™©ì— ë”°ë¼ ì ì ˆí•œ ë°˜ì‘ ìœ í˜•(ê³µê°, ì§ˆë¬¸, ë°©í–¥ ì œì‹œ)ì„ ì¡°í•©í•´ ì‚¬ìš©í•˜ì„¸ìš”.\n"
            "ë¬´ì¡°ê±´ ëª¨ë‘ í¬í•¨í•˜ì§€ ë§ê³ , ìì—°ìŠ¤ëŸ¬ìš´ 2ê°€ì§€ë¥¼ ì„ íƒí•˜ì„¸ìš”.\n"
            "ì‘ë‹µì€ 1~2ë¬¸ì¥ ì´ë‚´ë¡œ, ìœ ì‚¬ ë¬¸ì¥ ë°˜ë³µì€ ì ˆëŒ€ ê¸ˆì§€í•©ë‹ˆë‹¤.\n"
            "í˜ë¥´ì†Œë‚˜ì— ë§ëŠ” ë§íˆ¬ë¥¼ ìœ ì§€í•˜ì„¸ìš”."
        )

        return f"{base_prompt}\n{core_instruction}\n\n[ê³¼ê±° ëŒ€í™” ìš”ì•½]\n{memory}\n\n[ìƒë‹´ ì´ë¡  ìš”ì•½]\n{theory}\n\n[ì‚¬ìš©ì ì…ë ¥]\n{user_input}\n\n[ìƒë‹´ì ì‘ë‹µ]"

    def respond(self, user_input: str, message_log: list, member_id: str, theory: list = None, max_tokens: int = 150) -> str:
        with open("debug_log.txt", "a") as f:
            f.write(f"\nğŸ§© respond ì§„ì… | user_input: {user_input}\n")

        if is_first_entry(member_id, message_log):
            return "ì•ˆë…•í•˜ì„¸ìš”! ì²˜ìŒ ì˜¤ì…¨êµ°ìš”. í¸í•˜ê²Œ ì´ì•¼ê¸°í•´ ì£¼ì„¸ìš”. ğŸ˜Š"

        memory_raw = load_user_memory(member_id, message_log)
        memory = summarize_memory(memory_raw)

        self.detect_mode_via_llm(user_input, memory)

        theory_text = "\n".join([f"[{name}] {desc}" for name, desc in theory]) if isinstance(theory, list) else theory or ""
        system_prompt = self.build_prompt(user_input, memory, theory_text)

        with open("debug_log.txt", "a") as f:
            f.write("ğŸ§  build_prompt ì™„ë£Œ. GPT í˜¸ì¶œ ì‹œì‘...\n")

        try:
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "assistant", "content": memory},
                {"role": "user", "content": user_input}
            ]

            response = client.chat.completions.create(
                model="gpt-4o",
                messages=messages,
                temperature=0.4 if self.mode == "counseling" else 0.7,
                max_tokens=max_tokens
            )
            reply = response.choices[0].message.content.strip().replace('\n', ' ')

            with open("debug_log.txt", "a") as f:
                f.write(f"âœ… GPT ì‘ë‹µ ìˆ˜ì‹ : {reply}\n")

            if (
                len(reply) < 15 or
                any(x in reply.lower() for x in ["ì˜ ëª¨ë¥´ê² ì–´ìš”", "ì£„ì†¡", "ì–´ë ¤ì›Œìš”", "í™•ì‹¤í•˜ì§€ ì•Šì•„ìš”"])
            ):
                with open("debug_log.txt", "a") as f:
                    f.write("ğŸ§© ì‘ë‹µ í’ˆì§ˆ ë‚®ìŒ - fallback ë¬¸êµ¬ ë°˜í™˜\n")
                return "ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ ì´ì•¼ê¸°í•´ì£¼ì‹¤ ìˆ˜ ìˆì„ê¹Œìš”?"

            return reply

        except Exception as e:
            with open("debug_log.txt", "a") as f:
                f.write(f"âš ï¸ GPT í˜¸ì¶œ ì‹¤íŒ¨: {e}\n")
            return "ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ ì´ì•¼ê¸°í•´ì£¼ì‹¤ ìˆ˜ ìˆì„ê¹Œìš”?"
