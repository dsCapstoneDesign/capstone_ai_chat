import os
import json
import torch
from sentence_transformers import SentenceTransformer, util

class WikiSearcher:
    def __init__(self, model_name="intfloat/multilingual-e5-base"):
        base_dir = os.path.dirname(os.path.abspath(__file__))
        corpus_path = os.path.abspath(os.path.join(base_dir, "../dataset/hotpot/corpus/corpus.json"))

        if not os.path.exists(corpus_path):
            raise FileNotFoundError(f"[âŒ] corpus.json ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”: {corpus_path}")

        with open(corpus_path, "r", encoding="utf-8") as f:
            try:
                self.corpus = json.load(f)
            except json.JSONDecodeError:
                raise ValueError("[âŒ] corpus.jsonì´ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")

        if not isinstance(self.corpus, list):
            raise TypeError("[âŒ] corpus.jsonì€ list í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤ (ê° ì´ë¡ ì´ dictë¡œ êµ¬ì„±ëœ êµ¬ì¡°).")

        if not self.corpus:
            raise ValueError("âŒ corpus.jsonì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

        self.entries = []
        self.theory_map = {}
        for entry in self.corpus:
            if "ì´ë¡ ëª…" in entry and "ì„¤ëª…" in entry:
                text = f"{entry['ì´ë¡ ëª…']}: {entry['ì„¤ëª…']}"
                self.entries.append(text)
                self.theory_map[entry['ì´ë¡ ëª…']] = entry["ì„¤ëª…"]

        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model = SentenceTransformer(model_name, device=str(self.device))
        self.model.eval()

        print(f"ğŸ“˜ ìƒë‹´ ì´ë¡  ê°œìˆ˜: {len(self.entries)}ê°œ | ì„ë² ë”© ì¤‘...")

        self.embeddings = self.model.encode(
            self.entries,
            convert_to_tensor=True,
            show_progress_bar=True,
            normalize_embeddings=True
        ).to(self.device)

        print(f"âœ… ìƒë‹´ ì´ë¡  ì„ë² ë”© ì™„ë£Œ ({self.embeddings.shape})")

    def preprocess_query(self, query: str) -> str:
        query = query.strip()
        if len(query) < 6:
            return f"'{query}'ì— ë„ì›€ì´ ë˜ëŠ” ì‹¬ë¦¬ ìƒë‹´ ì´ë¡ "
        elif "?" not in query and not query.endswith("."):
            return f"{query}ì™€ ê´€ë ¨ëœ ì‹¬ë¦¬ìƒë‹´ ì´ë¡ "
        return query

    def search(self, query: str, top_k: int = 3) -> list[tuple[str, str]]:
        if not self.entries or not self.embeddings.shape[0]:
            return [("ê²€ìƒ‰ ì‹¤íŒ¨", "âŒ corpus ë‚´ìš©ì´ ë¹„ì–´ ìˆì–´ ê²€ìƒ‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")]

        formatted_query = f"query: {self.preprocess_query(query)}"
        try:
            query_embedding = self.model.encode(
                formatted_query,
                convert_to_tensor=True,
                normalize_embeddings=True
            ).to(self.device)

            similarity_scores = util.cos_sim(query_embedding, self.embeddings)[0]
            top_results = torch.topk(similarity_scores, k=min(top_k, len(self.entries)))

            results = []
            for idx in top_results.indices:
                entry = self.entries[idx]
                if ": " in entry:
                    theory, desc = entry.split(": ", 1)
                    results.append((theory.strip(), desc.strip()))

            return results if results else [("ê²€ìƒ‰ ì‹¤íŒ¨", "âŒ ìœ ì‚¬í•œ ì´ë¡ ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")]

        except Exception as e:
            print(f"âš ï¸ ìƒë‹´ ì´ë¡  ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return [("ê²€ìƒ‰ ì˜¤ë¥˜", str(e))]

    def keyword_search(self, keyword: str, top_k: int = 3) -> list[tuple[str, str]]:
        """
        'ì¶”ì²œìƒí™©' í•„ë“œì— ê°ì • í‚¤ì›Œë“œê°€ í¬í•¨ëœ ì´ë¡  ë°˜í™˜
        """
        matches = [
            (entry["ì´ë¡ ëª…"], entry["ì„¤ëª…"])
            for entry in self.corpus
            if "ì¶”ì²œìƒí™©" in entry and keyword in entry["ì¶”ì²œìƒí™©"]
        ]
        return matches[:top_k] if matches else [("ê²€ìƒ‰ ì‹¤íŒ¨", f"âŒ '{keyword}'ì— ë§ëŠ” ì´ë¡ ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")]
