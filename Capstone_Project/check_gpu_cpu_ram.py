import torch
import platform
import psutil

print("ğŸ§  ì‹œìŠ¤í…œ ì •ë³´ í™•ì¸")

# CPU ì •ë³´
print(f"ğŸ”¸ CPU: {platform.processor()}")
print(f"ğŸ”¸ CPU ì½”ì–´ ìˆ˜: {psutil.cpu_count(logical=False)} (ë¬¼ë¦¬), {psutil.cpu_count(logical=True)} (ë…¼ë¦¬)")

# RAM ì •ë³´
ram = psutil.virtual_memory()
print(f"ğŸ”¸ RAM: {round(ram.total / (1024**3), 2)} GB")

# GPU ì •ë³´ (PyTorch ê¸°ì¤€)
if torch.cuda.is_available():
    print("ğŸ”¹ GPU ì‚¬ìš© ê°€ëŠ¥ âœ…")
    print(f"ğŸ”¹ GPU ì´ë¦„: {torch.cuda.get_device_name(0)}")
    print(torch.cuda.get_device_name(0))
    print(f"ğŸ”¹ GPU ë©”ëª¨ë¦¬: {round(torch.cuda.get_device_properties(0).total_memory / (1024**3), 2)} GB")
else:
    print("ğŸ”¹ GPU ì‚¬ìš© ë¶ˆê°€ âŒ (torch.cuda.is_available() = False)")
